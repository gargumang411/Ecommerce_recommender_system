{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "M1v1W731ilKU",
    "outputId": "61a4e3f1-7a8d-4aac-8886-638207367c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "9f1bf9c66bbb4eda932a9e4eb9f75f04",
       "pip_warning": {
        "packages": [
         "nvidia"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch  # Ensure latest PyTorch (includes CUDA support for GPU)\n",
    "!pip install pandas numpy  # For data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPalMNLbpCFI",
    "outputId": "054d8b94-f39b-4bf2-d9fd-6d98289a068b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# One-time per session to bring it to fast local storage\n",
    "\n",
    "!cp \"/content/drive/MyDrive/Electronics_5.json.gz\" /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBCvt4gLtIn3",
    "outputId": "f7197f5c-a701-48b6-876c-c58cb60e8a18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw------- 1 root root 1.2G May 21 20:46 /content/Electronics_5.json.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /content/Electronics_5.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zx4XynEroDbN",
    "outputId": "3a4c28de-102b-445a-99b6-8a806e146c73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Total number of reviews (rows): 6738382\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "file_path = '/content/Electronics_5.json.gz'\n",
    "\n",
    "line_count = 0\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "    for _ in f:\n",
    "        line_count += 1\n",
    "\n",
    "print(f\"ðŸ“¦ Total number of reviews (rows): {line_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fu4mI3XuNRs",
    "outputId": "76fc1191-529b-4341-dd28-69386fcbbed8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved to /content/processed_interactions_realistic.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = '/content/Electronics_5.json.gz'\n",
    "\n",
    "# Step 1: Read in chunks, only needed columns\n",
    "chunks = []\n",
    "chunk_size = 250_000\n",
    "\n",
    "reader = pd.read_json(file_path, lines=True, compression='gzip', chunksize=chunk_size)\n",
    "\n",
    "for chunk in reader:\n",
    "    chunk = chunk[['reviewerID', 'asin', 'overall']]\n",
    "    chunk.columns = ['user_id', 'item_id', 'rating']\n",
    "    chunks.append(chunk)\n",
    "\n",
    "# Step 2: Concatenate into single DataFrame\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "del chunks  # Free memory\n",
    "\n",
    "# Step 3: Sort and assign interaction_status\n",
    "df = df.sort_values(by='rating', ascending=False).reset_index(drop=True)\n",
    "total_rows = len(df)\n",
    "\n",
    "df.loc[:int(0.025 * total_rows), 'interaction_status'] = 1.0\n",
    "df.loc[int(0.025 * total_rows):int(0.10 * total_rows), 'interaction_status'] = 0.6\n",
    "df.loc[int(0.10 * total_rows):int(0.35 * total_rows), 'interaction_status'] = 0.3\n",
    "df.loc[int(0.35 * total_rows):, 'interaction_status'] = 0.0\n",
    "\n",
    "# Step 4: Final save\n",
    "final_df = df[['user_id', 'item_id', 'interaction_status']]\n",
    "final_df.to_csv('/content/processed_interactions_realistic.csv', index=False)\n",
    "\n",
    "print(\"âœ… Saved to /content/processed_interactions_realistic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcOvOeERz-4u",
    "outputId": "744b63b9-23be-4205-9ce5-a1a8656a1451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          user_id     item_id  interaction_status\n",
      "0  A1FGCIRPRNZWD5  B01HJF704M                 1.0\n",
      "1   AAP7PPBU72QFM  0151004714                 1.0\n",
      "2   AJJ7VX2L91X2W  B01HJH40WU                 1.0\n",
      "3  A1ER5AYS3FQ9O3  0151004714                 1.0\n",
      "4  A1T17LMQABMBN5  0151004714                 1.0\n",
      "5  A2HUZO7MQAY5I2  B01HJH40WU                 1.0\n",
      "6   AG3DXG002QSXP  B01HJA3OUG                 1.0\n",
      "7   AE50B0MLAS1B9  B01HJA3OUG                 1.0\n",
      "8  A2L12USPGEMCTM  B01HIZEW1C                 1.0\n",
      "9  A2RU0H9MD4IH5M  B01HIZEW1C                 1.0\n"
     ]
    }
   ],
   "source": [
    "# Load the saved dataset\n",
    "df_sample = pd.read_csv('/content/processed_interactions_realistic.csv')\n",
    "\n",
    "# Show first 10 rows\n",
    "print(df_sample.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1b3a5d2ui9p",
    "outputId": "4912779a-3e8a-4416-e587-0fe02c084b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      count  percentage\n",
      "interaction_status                     \n",
      "0.0                 4379949        65.0\n",
      "0.3                 1684595        25.0\n",
      "0.6                  505379         7.5\n",
      "1.0                  168459         2.5\n"
     ]
    }
   ],
   "source": [
    "#1 means brought\n",
    "#.6 means added to wishlist/cart\n",
    "#.3 means intereacted\n",
    "#0 means ignored\n",
    "interaction_counts = df['interaction_status'].value_counts().sort_index()\n",
    "interaction_percentages = df['interaction_status'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "# Combine into one table\n",
    "summary = pd.DataFrame({\n",
    "    'count': interaction_counts,\n",
    "    'percentage': interaction_percentages.round(2)\n",
    "})\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5UNqozP0Yb7",
    "outputId": "bc95318e-435d-4f44-dcb1-6b1e7a483915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 728678, Number of items: 159748\n",
      "Train size: 5963468, Val size: 673838, Test size: 101076\n",
      "Using device: cuda\n",
      "Starting training...\n",
      "Epoch 1/3, Train Loss: 0.1801, Val Loss: 0.1795, Val MAE: 0.3950\n",
      "Epoch 2/3, Train Loss: 0.1795, Val Loss: 0.1795, Val MAE: 0.3950\n",
      "Epoch 3/3, Train Loss: 0.1795, Val Loss: 0.1795, Val MAE: 0.3950\n",
      "Test Loss: 0.1792, Test MAE: 0.3946\n",
      "Precision@10: 0.0110\n",
      "âœ… Metrics saved to /content/training_metrics.csv\n",
      "âœ… Model saved to /content/two_tower_model.pth\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Step 1:  Encode user_id and item_id\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "df['user_id'] = user_encoder.fit_transform(df['user_id'])\n",
    "df['item_id'] = item_encoder.fit_transform(df['item_id'])\n",
    "\n",
    "# Number of unique users and items\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_items = len(item_encoder.classes_)\n",
    "print(f\"Number of users: {num_users}, Number of items: {num_items}\")\n",
    "\n",
    "# Step 2: Split into train, validation, and test sets (~88.5-10-1.5)\n",
    "train_df, temp_df = train_test_split(df, train_size=0.885, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, train_size=(0.10 / 0.115), random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}\")\n",
    "\n",
    "# Step 3: Create a custom Dataset\n",
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = torch.tensor(df['user_id'].values, dtype=torch.long)\n",
    "        self.item_ids = torch.tensor(df['item_id'].values, dtype=torch.long)\n",
    "        self.labels = torch.tensor(df['interaction_status'].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = InteractionDataset(train_df)\n",
    "val_dataset = InteractionDataset(val_df)\n",
    "test_dataset = InteractionDataset(test_df)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Step 4: Define the Enhanced Two-Tower Model\n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=128):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        # User tower\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.user_fc1 = nn.Linear(embedding_dim, embedding_dim // 2)\n",
    "        self.user_bn1 = nn.BatchNorm1d(embedding_dim // 2)\n",
    "        # Item tower\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.item_fc1 = nn.Linear(embedding_dim, embedding_dim // 2)\n",
    "        self.item_bn1 = nn.BatchNorm1d(embedding_dim // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        # User tower\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        user_out = self.user_fc1(user_emb)\n",
    "        user_out = self.user_bn1(user_out)\n",
    "        user_out = self.relu(user_out)\n",
    "        # Item tower\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        item_out = self.item_fc1(item_emb)\n",
    "        item_out = self.item_bn1(item_out)\n",
    "        item_out = self.relu(item_out)\n",
    "        # Dot product\n",
    "        prediction = (user_out * item_out).sum(dim=1)\n",
    "        return torch.sigmoid(prediction)\n",
    "\n",
    "# Step 5: Initialize model, loss, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "embedding_dim = 128\n",
    "model = TwoTowerModel(num_users, num_items, embedding_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 6: Training Loop with Logging\n",
    "num_epochs = 3\n",
    "print(\"Starting training...\")\n",
    "metrics = []\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for user_ids, item_ids, labels in train_loader:\n",
    "        user_ids, item_ids, labels = user_ids.to(device), item_ids.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user_ids, item_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # Debug gradient\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         print(f\"{name} gradient norm: {param.grad.norm()}\")\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * user_ids.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_mae = 0.0\n",
    "    with torch.no_grad():\n",
    "        for user_ids, item_ids, labels in val_loader:\n",
    "            user_ids, item_ids, labels = user_ids.to(device), item_ids.to(device), labels.to(device)\n",
    "            outputs = model(user_ids, item_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            mae = torch.mean(torch.abs(outputs - labels))\n",
    "            val_loss += loss.item() * user_ids.size(0)\n",
    "            val_mae += mae.item() * user_ids.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_mae /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.4f}\")\n",
    "\n",
    "    metrics.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae\n",
    "    })\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'user_encoder': user_encoder,\n",
    "            'item_encoder': item_encoder,\n",
    "            'embedding_dim': embedding_dim\n",
    "        }, '/content/best_two_tower_model.pth')\n",
    "\n",
    "# Step 7: Test Performance with Precision@10\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_mae = 0.0\n",
    "# For Precision@10: Predict scores for test set, rank, and check top-10\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "with torch.no_grad():\n",
    "    for user_ids, item_ids, labels in test_loader:\n",
    "        user_ids, item_ids, labels = user_ids.to(device), item_ids.to(device), labels.to(device)\n",
    "        outputs = model(user_ids, item_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        mae = torch.mean(torch.abs(outputs - labels))\n",
    "        test_loss += loss.item() * user_ids.size(0)\n",
    "        test_mae += mae.item() * user_ids.size(0)\n",
    "        test_predictions.extend(outputs.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_mae /= len(test_loader.dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "\n",
    "# Precision@10: For each user, rank items and check top-10\n",
    "test_df_with_preds = test_df.copy()\n",
    "test_df_with_preds['prediction'] = test_predictions\n",
    "test_df_with_preds['label'] = test_labels\n",
    "# Group by user and get top-10 predictions\n",
    "top_n = 10\n",
    "precision_at_n = 0\n",
    "user_groups = test_df_with_preds.groupby('user_id')\n",
    "for user_id, group in user_groups:\n",
    "    group = group.sort_values('prediction', ascending=False)\n",
    "    top_n_items = group.head(top_n)\n",
    "    # Consider \"bought\" (1.0) or \"added to cart\" (0.6) as relevant\n",
    "    relevant_items = len(top_n_items[top_n_items['label'] >= 0.6])\n",
    "    precision_at_n += relevant_items / top_n\n",
    "precision_at_n /= len(user_groups)\n",
    "print(f\"Precision@10: {precision_at_n:.4f}\")\n",
    "\n",
    "# Log test metrics\n",
    "metrics.append({\n",
    "    'epoch': 'final',\n",
    "    'test_loss': test_loss,\n",
    "    'test_mae': test_mae,\n",
    "    'precision_at_10': precision_at_n\n",
    "})\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df.to_csv('/content/training_metrics.csv', index=False)\n",
    "print(\"âœ… Metrics saved to /content/training_metrics.csv\")\n",
    "\n",
    "# Step 8: Save the final model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'user_encoder': user_encoder,\n",
    "    'item_encoder': item_encoder,\n",
    "    'embedding_dim': embedding_dim\n",
    "}, '/content/two_tower_model.pth')\n",
    "print(\"âœ… Model saved to /content/two_tower_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx-euW0W6vTq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
